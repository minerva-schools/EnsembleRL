# List of issues:
+ I initially had trouble using the 2019 version of Unity, as it told me that I could not start my package manager due to antivirus restrictions. This issue was solved after I installed the 2018 version first, and then the 2019 version.
+ 3DBallLearn.nn name did not exist in the 2019 version of unity, probably just a version difference from the tutorial?
+ The Basic Guide tutorial stated that ‘each Agent under each 3DBall in the Hierarchy windows now contains 3DBall as Model on the Behavior Parameters’ This statement initially confused me, because there only appeared to be one agent preprogrammed. This was a helpful confusion because I then realized that there is a difference between a prefab and a scene, and that prefabs can be reused in scenes.
+ helpful line re above issue: ‘Note that Agents sharing the same Behavior Name must be agents of the same type using the same Behavior Parameters’
+ I am still confused by this line: ‘In order to setup the Agents for Training, you will need to edit the Behavior Name under BehaviorParameters in the Agent Inspector window. The Behavior Name is used to group agents per behaviors. Note that Agents sharing the same Behavior Name must be agents of the same type using the same Behavior Parameters. You can make sure all your agents have the same Behavior Parameters using Prefabs. The Behavior Name corresponds to the name of the model that will be generated by the training process and is used to select the hyperparameters from the training configuration file.’
*Confusion*: does the behavior name just group the agents per behaviors, or do I need to make sure the behavior name and behavior parameter model uses the same name??
+ The roll-a-ball tutorial went pretty okay, except struggling to find where everything was in the Unity editor etc. But I guess that that's just part of the learning curve. Attached is a video of me playing the resulting game: 

# Video of my roll-a-ball app: 
https://drive.google.com/open?id=1ebPqRH-SrfhXobzlpW_uKF9cuELDHWVO

# Results from Basic Guide Tutorial:

INFO:mlagents.trainers: firstRun: 3DBall: Step: 1000. Time Elapsed: 26.830 s Mean Reward: 1.150. Std of Reward: 0.733. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 2000. Time Elapsed: 39.654 s Mean Reward: 1.285. Std of Reward: 0.847. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 3000. Time Elapsed: 53.036 s Mean Reward: 1.692. Std of Reward: 1.100. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 4000. Time Elapsed: 65.293 s Mean Reward: 2.425. Std of Reward: 1.759. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 5000. Time Elapsed: 77.623 s Mean Reward: 3.326. Std of Reward: 2.526. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 6000. Time Elapsed: 90.222 s Mean Reward: 6.001. Std of Reward: 5.982. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 7000. Time Elapsed: 102.810 s Mean Reward: 11.639. Std of Reward: 10.968. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 8000. Time Elapsed: 119.858 s Mean Reward: 22.191. Std of Reward: 18.518. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 9000. Time Elapsed: 139.074 s Mean Reward: 48.888. Std of Reward: 27.783. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 10000. Time Elapsed: 155.254 s Mean Reward: 68.517. Std of Reward: 34.013. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 11000. Time Elapsed: 170.740 s Mean Reward: 71.220. Std of Reward: 36.634. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 12000. Time Elapsed: 188.917 s Mean Reward: 95.046. Std of Reward: 15.152. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 13000. Time Elapsed: 203.824 s Mean Reward: 87.423. Std of Reward: 29.943. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 14000. Time Elapsed: 216.514 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 15000. Time Elapsed: 231.266 s Mean Reward: 85.220. Std of Reward: 29.602. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 16000. Time Elapsed: 244.398 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 17000. Time Elapsed: 256.819 s Mean Reward: 92.977. Std of Reward: 24.329. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 18000. Time Elapsed: 269.057 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 19000. Time Elapsed: 281.381 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 20000. Time Elapsed: 293.445 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 21000. Time Elapsed: 305.333 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 22000. Time Elapsed: 320.105 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 23000. Time Elapsed: 333.561 s Mean Reward: 92.446. Std of Reward: 26.167. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 24000. Time Elapsed: 346.029 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 25000. Time Elapsed: 358.931 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 26000. Time Elapsed: 374.921 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 27000. Time Elapsed: 393.803 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 28000. Time Elapsed: 419.136 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 29000. Time Elapsed: 443.727 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 30000. Time Elapsed: 461.802 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 31000. Time Elapsed: 486.622 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 32000. Time Elapsed: 511.458 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 33000. Time Elapsed: 540.119 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 34000. Time Elapsed: 566.367 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 35000. Time Elapsed: 591.296 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 36000. Time Elapsed: 617.632 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 37000. Time Elapsed: 645.981 s Mean Reward: 92.431. Std of Reward: 26.221. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 38000. Time Elapsed: 671.772 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 39000. Time Elapsed: 696.684 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 40000. Time Elapsed: 720.596 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 41000. Time Elapsed: 745.327 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 42000. Time Elapsed: 772.547 s Mean Reward: 92.377. Std of Reward: 26.407. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 43000. Time Elapsed: 801.294 s Mean Reward: 100.000. Std of Reward: 0.000. Training.
INFO:mlagents.trainers: firstRun: 3DBall: Step: 44000. Time Elapsed: 830.995 s Mean Reward: 100.000. Std of Reward: 0.000. Training.

What I modified after training the model, to use my newly trained model:
![image](https://drive.google.com/uc?export=view&id=1bNJQlUXwyEEqqTit9pPDqc_OgLdtGIMg)


Screenshot of my balanced(unlike me) agents:

![image](https://drive.google.com/uc?export=view&id=1Bai75-vH3OnU6IDtxd-Zx9FKrRQkV0n3)
